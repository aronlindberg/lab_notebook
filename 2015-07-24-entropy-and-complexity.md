# Entropy and Complexity

These last few days I have been in a data analysis funk that is becoming familiar. This happens when I have a strong (at least in my mind) working hypothesis about how some relationships are going to work out, and then the data will not cooperate. For example, last December I was working on a paper from my dissertation on open source software lifecycles. I was conducting a cluster analysis, and I was fixed on the idea of getting 4 clusters. However, no matter how I massaged the data, it would give me 2 clusters, or perhaps 3. Eventually I realized that I had to change my working hypothesis, and build a theory that actually fit with the data.

Now I seem to be there again. I have been working under the hypothesis that code complexity, as captured by the the degree of interdependence between files should be mirroed by the complexity of code - meaning the connections between different action. However, this does not seem to be the case. Rather, complexity of code seems to be quite strongly related to entropy, meaning the efficient coverage of routine enactments which serve to write working code.

However, it seems that I still have a story here. The complexity of routine enactments can be said to not be a counter to code complexity, but rather to some form of social complexity. Our qualitative coding seems to show that when developers need to ask questions, make clarifications, cross-validate solutions across multiple technical platforms and hardware configurations, then routine complexity increases substantially.

Hence, we have code complexity, which is countered by routine entropy, and social complexity (or subjectively/cognitive perceived complexity...of code?), which is countered by routine complexity.
